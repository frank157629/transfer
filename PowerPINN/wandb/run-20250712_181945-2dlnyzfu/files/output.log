GFL_2nd_order data
Loading data from:  ./data/GFL_2nd_order/dataset_v1.pkl
/Users/nbhsbgnb/PycharmProjects/PythonProject/PowerPINN/src/nn/nn_dataset.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  training_sample = torch.tensor(training_sample, dtype=torch.float32) # convert the trajectory to tensor
Number of training samples:  80000 Number of validation samples:  10000 Number of testing samples:  10000
Number of different initial conditions for collocation points:  100
['delta', 'omega'] Variables
[[-3.14159, 3.14159], [-60, 60]] Set of values for init conditions
[10, 10] Iterations per value
Shape: (100, 2)
Selected deep learning model:  PinnA
Number of labeled training data: 79920 Number of collocation points: 99900 Number of collocation points (IC): 100 Number of validation data: 10000
Weights initialized as:  [1, 0.001, 0.0001, 0.001]  are updated with scheme:  Static
getting in training
type:  validation, total_traj: 10, max_traj 20
Epoch [50/15000], Loss: 639.5328, Loss_data: 541.1100, Loss_dt: 66544.6641, Loss_pinn: 318780.3438 , Loss_pinn_ic : 0.0000 488.0407409667969 84855.953125
type:  validation, total_traj: 10, max_traj 20
Epoch [100/15000], Loss: 597.1506, Loss_data: 499.5615, Loss_dt: 66475.0000, Loss_pinn: 311141.4375 , Loss_pinn_ic : 0.0000 445.6348876953125 84785.296875
wandb: Ctrl + C detected. Stopping sweep.
