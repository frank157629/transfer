GFL_2nd_order data
Loading data from:  ./data/GFL_2nd_order/dataset_v1.pkl
/Users/nbhsbgnb/PycharmProjects/PythonProject/PowerPINN/src/nn/nn_dataset.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  training_sample = torch.tensor(training_sample, dtype=torch.float32) # convert the trajectory to tensor
Number of training samples:  80000 Number of validation samples:  10000 Number of testing samples:  10000
Number of different initial conditions for collocation points:  100
['delta', 'omega'] Variables
[[-3.14159, 3.14159], [-60, 60]] Set of values for init conditions
[10, 10] Iterations per value
Shape: (100, 2)
Selected deep learning model:  DynamicNN
Number of labeled training data: 80000 Number of collocation points: 100000 Number of collocation points (IC): 100 Number of validation data: 10000
Weights initialized as:  [1, 0.001, 0.0001, 0.001]  are updated with scheme:  Static
getting in training
Validation loss decreased (inf --> 175.697723).  Saving model ...
type:  validation, total_traj: 10, max_traj 20
Epoch [50/15000], Loss: 195.7195, Loss_data: 127.9431, Loss_dt: 67125.0000, Loss_pinn: 657.2738 , Loss_pinn_ic : 585.7110 170.28875732421875 85136.4921875
type:  validation, total_traj: 10, max_traj 20
Epoch [100/15000], Loss: 194.7272, Loss_data: 126.9479, Loss_dt: 67124.2734, Loss_pinn: 701.4121 , Loss_pinn_ic : 584.8452 169.43421936035156 85136.609375
type:  validation, total_traj: 10, max_traj 20
Epoch [150/15000], Loss: 193.2528, Loss_data: 125.4677, Loss_dt: 67119.4375, Loss_pinn: 851.3149 , Loss_pinn_ic : 580.5526 167.4062957763672 85132.9140625
type:  validation, total_traj: 10, max_traj 20
Epoch [200/15000], Loss: 190.9796, Loss_data: 123.2097, Loss_dt: 67102.8750, Loss_pinn: 964.1345 , Loss_pinn_ic : 570.5402 164.41188049316406 85118.109375
type:  validation, total_traj: 10, max_traj 20
Epoch [250/15000], Loss: 187.0053, Loss_data: 119.3242, Loss_dt: 67035.5156, Loss_pinn: 1041.5728 , Loss_pinn_ic : 541.3986 160.16285705566406 85059.421875
type:  validation, total_traj: 10, max_traj 20
Epoch [300/15000], Loss: 178.1061, Loss_data: 110.8530, Loss_dt: 66665.2578, Loss_pinn: 1316.8741 , Loss_pinn_ic : 456.1825 151.4276580810547 84790.828125
type:  validation, total_traj: 10, max_traj 20
Epoch [350/15000], Loss: 166.2910, Loss_data: 100.2439, Loss_dt: 65595.7031, Loss_pinn: 1200.5712 , Loss_pinn_ic : 331.4093 138.93267822265625 84270.2109375
type:  validation, total_traj: 10, max_traj 20
Epoch [400/15000], Loss: 151.7580, Loss_data: 88.4974, Loss_dt: 62905.1094, Loss_pinn: 1318.0275 , Loss_pinn_ic : 223.6867 123.91812133789062 82177.890625
type:  validation, total_traj: 10, max_traj 20
Epoch [450/15000], Loss: 134.8099, Loss_data: 76.4293, Loss_dt: 58064.4375, Loss_pinn: 1553.9983 , Loss_pinn_ic : 160.7702 106.38147735595703 76814.78125
type:  validation, total_traj: 10, max_traj 20
Epoch [500/15000], Loss: 120.8450, Loss_data: 67.7175, Loss_dt: 52785.6719, Loss_pinn: 2165.6985 , Loss_pinn_ic : 125.2483 95.80317687988281 73275.4921875
type:  validation, total_traj: 10, max_traj 20
Epoch [550/15000], Loss: 112.8885, Loss_data: 62.7600, Loss_dt: 49784.5430, Loss_pinn: 2226.9849 , Loss_pinn_ic : 121.2495 88.44773864746094 68938.2109375
type:  validation, total_traj: 10, max_traj 20
Epoch [600/15000], Loss: 102.5989, Loss_data: 56.4313, Loss_dt: 45895.6758, Loss_pinn: 1510.7213 , Loss_pinn_ic : 120.8519 84.71002960205078 67525.8125
type:  validation, total_traj: 10, max_traj 20
Epoch [650/15000], Loss: 95.5523, Loss_data: 52.4343, Loss_dt: 42854.6250, Loss_pinn: 1588.2383 , Loss_pinn_ic : 104.6340 80.469970703125 63997.5859375
type:  validation, total_traj: 10, max_traj 20
Epoch [700/15000], Loss: 88.5764, Loss_data: 48.9236, Loss_dt: 39354.4688, Loss_pinn: 2352.1064 , Loss_pinn_ic : 63.1458 79.03507232666016 61661.9453125
type:  validation, total_traj: 10, max_traj 20
Epoch [750/15000], Loss: 82.6975, Loss_data: 45.8494, Loss_dt: 36518.3867, Loss_pinn: 2753.3594 , Loss_pinn_ic : 54.3390 79.63935089111328 61554.01953125
type:  validation, total_traj: 10, max_traj 20
Epoch [800/15000], Loss: 77.5263, Loss_data: 43.2207, Loss_dt: 33945.7656, Loss_pinn: 3165.7415 , Loss_pinn_ic : 43.2235 78.57939910888672 60090.16796875
type:  validation, total_traj: 10, max_traj 20
Epoch [850/15000], Loss: 72.3743, Loss_data: 40.4418, Loss_dt: 31558.8418, Loss_pinn: 3338.5393 , Loss_pinn_ic : 39.8374 78.04568481445312 58949.18359375
type:  validation, total_traj: 10, max_traj 20
Epoch [900/15000], Loss: 68.0718, Loss_data: 38.1197, Loss_dt: 29546.5840, Loss_pinn: 3668.4880 , Loss_pinn_ic : 38.6063 77.59525299072266 57789.89453125
type:  validation, total_traj: 10, max_traj 20
Epoch [950/15000], Loss: 63.9482, Loss_data: 35.8738, Loss_dt: 27628.6055, Loss_pinn: 4146.5596 , Loss_pinn_ic : 31.0351 75.79773712158203 55669.86328125
type:  validation, total_traj: 10, max_traj 20
Epoch [1000/15000], Loss: 60.2889, Loss_data: 33.9506, Loss_dt: 25840.4902, Loss_pinn: 4699.2358 , Loss_pinn_ic : 27.8744 76.25418853759766 55242.63671875
type:  validation, total_traj: 10, max_traj 20
Epoch [1050/15000], Loss: 57.4217, Loss_data: 32.4947, Loss_dt: 24389.7852, Loss_pinn: 5086.2856 , Loss_pinn_ic : 28.5070 77.47257995605469 55801.7734375
type:  validation, total_traj: 10, max_traj 20
Epoch [1100/15000], Loss: 54.2187, Loss_data: 30.7634, Loss_dt: 22895.1953, Loss_pinn: 5362.1685 , Loss_pinn_ic : 23.8507 77.92112731933594 56403.22265625
type:  validation, total_traj: 10, max_traj 20
Epoch [1150/15000], Loss: 51.8934, Loss_data: 29.4591, Loss_dt: 21852.3457, Loss_pinn: 5606.2729 , Loss_pinn_ic : 21.3772 79.13829040527344 57353.61328125
type:  validation, total_traj: 10, max_traj 20
Epoch [1200/15000], Loss: 49.4397, Loss_data: 28.2123, Loss_dt: 20632.2207, Loss_pinn: 5748.4634 , Loss_pinn_ic : 20.3561 80.87565612792969 58373.25390625
type:  validation, total_traj: 10, max_traj 20
Epoch [1250/15000], Loss: 47.3333, Loss_data: 27.1067, Loss_dt: 19619.2324, Loss_pinn: 5878.3970 , Loss_pinn_ic : 19.5336 82.60356140136719 59636.5078125
type:  validation, total_traj: 10, max_traj 20
Epoch [1300/15000], Loss: 45.3114, Loss_data: 26.0238, Loss_dt: 18670.1309, Loss_pinn: 5985.6309 , Loss_pinn_ic : 18.8808 84.59222412109375 61385.26953125
type:  validation, total_traj: 10, max_traj 20
Epoch [1350/15000], Loss: 43.4070, Loss_data: 25.0093, Loss_dt: 17775.6934, Loss_pinn: 6033.4370 , Loss_pinn_ic : 18.6294 86.5177230834961 63132.60546875
type:  validation, total_traj: 10, max_traj 20
Epoch [1400/15000], Loss: 41.4772, Loss_data: 23.9627, Loss_dt: 16888.1543, Loss_pinn: 6080.1724 , Loss_pinn_ic : 18.3291 90.0482406616211 65750.171875
type:  validation, total_traj: 10, max_traj 20
Epoch [1450/15000], Loss: 39.7954, Loss_data: 23.1036, Loss_dt: 16059.5225, Loss_pinn: 6143.1870 , Loss_pinn_ic : 17.9500 92.33892822265625 67041.640625
type:  validation, total_traj: 10, max_traj 20
Epoch [1500/15000], Loss: 38.3752, Loss_data: 22.3946, Loss_dt: 15347.6982, Loss_pinn: 6149.0820 , Loss_pinn_ic : 18.0482 94.38028717041016 68181.2109375
type:  validation, total_traj: 10, max_traj 20
Epoch [1550/15000], Loss: 36.9161, Loss_data: 21.6737, Loss_dt: 14616.8838, Loss_pinn: 6072.9214 , Loss_pinn_ic : 18.1969 97.26103973388672 70174.2421875
type:  validation, total_traj: 10, max_traj 20
Epoch [1600/15000], Loss: 35.7715, Loss_data: 21.1108, Loss_dt: 14043.1172, Loss_pinn: 5986.7681 , Loss_pinn_ic : 18.8140 100.12323760986328 72198.40625
type:  validation, total_traj: 10, max_traj 20
Epoch [1650/15000], Loss: 34.5250, Loss_data: 20.5522, Loss_dt: 13361.5723, Loss_pinn: 5925.1626 , Loss_pinn_ic : 18.7104 101.06373596191406 72551.7890625
type:  validation, total_traj: 10, max_traj 20
Epoch [1700/15000], Loss: 33.7762, Loss_data: 20.2526, Loss_dt: 12914.8398, Loss_pinn: 5900.3667 , Loss_pinn_ic : 18.7710 100.55792236328125 71800.2890625
type:  validation, total_traj: 10, max_traj 20
Epoch [1750/15000], Loss: 32.6778, Loss_data: 19.8147, Loss_dt: 12253.9375, Loss_pinn: 5897.9912 , Loss_pinn_ic : 19.3708 101.49516296386719 72042.734375
type:  validation, total_traj: 10, max_traj 20
Epoch [1800/15000], Loss: 31.0408, Loss_data: 19.1674, Loss_dt: 11269.2959, Loss_pinn: 5850.1758 , Loss_pinn_ic : 18.9882 103.22976684570312 72442.0234375
type:  validation, total_traj: 10, max_traj 20
Epoch [1850/15000], Loss: 31.4940, Loss_data: 19.3725, Loss_dt: 11514.6738, Loss_pinn: 5863.2046 , Loss_pinn_ic : 20.5399 101.28347778320312 69784.34375
type:  validation, total_traj: 10, max_traj 20
Epoch [1900/15000], Loss: 28.6938, Loss_data: 18.2955, Loss_dt: 9795.0234, Loss_pinn: 5857.6592 , Loss_pinn_ic : 17.4744 105.0635986328125 71095.4453125
type:  validation, total_traj: 10, max_traj 20
Epoch [1950/15000], Loss: 27.5337, Loss_data: 17.8457, Loss_dt: 9081.2500, Loss_pinn: 5905.9209 , Loss_pinn_ic : 16.1818 105.38175964355469 69897.1484375
type:  validation, total_traj: 10, max_traj 20
Epoch [2000/15000], Loss: 27.0629, Loss_data: 17.6525, Loss_dt: 8790.7607, Loss_pinn: 6033.2451 , Loss_pinn_ic : 16.3613 103.98310089111328 67415.9453125
type:  validation, total_traj: 10, max_traj 20
Epoch [2050/15000], Loss: 25.9851, Loss_data: 17.2341, Loss_dt: 8117.3633, Loss_pinn: 6175.8745 , Loss_pinn_ic : 16.0552 104.91497802734375 66947.5078125
type:  validation, total_traj: 10, max_traj 20
Epoch [2100/15000], Loss: 24.6118, Loss_data: 16.7100, Loss_dt: 7246.1909, Loss_pinn: 6410.0703 , Loss_pinn_ic : 14.6343 104.28409576416016 65682.1796875
type:  validation, total_traj: 10, max_traj 20
Epoch [2150/15000], Loss: 22.9997, Loss_data: 16.0861, Loss_dt: 6232.9697, Loss_pinn: 6673.3193 , Loss_pinn_ic : 13.3244 105.32540893554688 66044.7109375
type:  validation, total_traj: 10, max_traj 20
Epoch [2200/15000], Loss: 21.7743, Loss_data: 15.6223, Loss_dt: 5450.5200, Loss_pinn: 6888.8789 , Loss_pinn_ic : 12.6149 106.74506378173828 66735.8203125
type:  validation, total_traj: 10, max_traj 20
Epoch [2250/15000], Loss: 21.2768, Loss_data: 15.3990, Loss_dt: 5150.9155, Loss_pinn: 7140.6348 , Loss_pinn_ic : 12.9029 108.16249084472656 67600.25
type:  validation, total_traj: 10, max_traj 20
Epoch [2300/15000], Loss: 19.7951, Loss_data: 14.8435, Loss_dt: 4218.2124, Loss_pinn: 7208.1372 , Loss_pinn_ic : 12.6120 105.65190124511719 65271.01171875
type:  validation, total_traj: 10, max_traj 20
Epoch [2350/15000], Loss: 20.3650, Loss_data: 15.0164, Loss_dt: 4600.8457, Loss_pinn: 7326.7852 , Loss_pinn_ic : 15.0789 104.31189727783203 64171.62890625
type:  validation, total_traj: 10, max_traj 20
Epoch [2400/15000], Loss: 18.6402, Loss_data: 14.3696, Loss_dt: 3514.5818, Loss_pinn: 7429.9414 , Loss_pinn_ic : 13.0541 104.83857727050781 64476.15234375
type:  validation, total_traj: 10, max_traj 20
Epoch [2450/15000], Loss: 18.5907, Loss_data: 14.3247, Loss_dt: 3506.5029, Loss_pinn: 7455.3652 , Loss_pinn_ic : 14.0196 104.11510467529297 64072.6171875
type:  validation, total_traj: 10, max_traj 20
Epoch [2500/15000], Loss: 17.3124, Loss_data: 13.8472, Loss_dt: 2693.5085, Loss_pinn: 7591.4668 , Loss_pinn_ic : 12.4976 105.94445037841797 65361.875
type:  validation, total_traj: 10, max_traj 20
Epoch [2550/15000], Loss: 16.9471, Loss_data: 13.6891, Loss_dt: 2483.1890, Loss_pinn: 7620.8374 , Loss_pinn_ic : 12.7240 104.86198425292969 64819.92578125
type:  validation, total_traj: 10, max_traj 20
Epoch [2600/15000], Loss: 16.8515, Loss_data: 13.6102, Loss_dt: 2451.9453, Loss_pinn: 7767.2432 , Loss_pinn_ic : 12.6771 108.09915924072266 67138.3203125
type:  validation, total_traj: 10, max_traj 20
Epoch [2650/15000], Loss: 16.2794, Loss_data: 13.3567, Loss_dt: 2115.0571, Loss_pinn: 7949.1699 , Loss_pinn_ic : 12.7218 106.13455963134766 65878.21875
type:  validation, total_traj: 10, max_traj 20
Epoch [2700/15000], Loss: 16.5144, Loss_data: 13.3586, Loss_dt: 2321.6699, Loss_pinn: 8199.1572 , Loss_pinn_ic : 14.2047 103.9153823852539 64344.54296875
type:  validation, total_traj: 10, max_traj 20
Epoch [2750/15000], Loss: 16.6573, Loss_data: 13.2919, Loss_dt: 2486.2920, Loss_pinn: 8641.1729 , Loss_pinn_ic : 15.0496 102.94454193115234 63792.59765625
type:  validation, total_traj: 10, max_traj 20
Epoch [2800/15000], Loss: 15.4025, Loss_data: 12.6811, Loss_dt: 1751.0065, Loss_pinn: 9574.0439 , Loss_pinn_ic : 13.0011 106.70912170410156 66191.3984375
type:  validation, total_traj: 10, max_traj 20
Epoch [2850/15000], Loss: 14.9491, Loss_data: 12.2270, Loss_dt: 1664.0830, Loss_pinn: 10445.3916 , Loss_pinn_ic : 13.4215 104.6532211303711 65106.58203125
type:  validation, total_traj: 10, max_traj 20
Epoch [2900/15000], Loss: 14.6181, Loss_data: 11.8996, Loss_dt: 1637.9545, Loss_pinn: 10664.1152 , Loss_pinn_ic : 14.1067 105.69363403320312 65520.18359375
type:  validation, total_traj: 10, max_traj 20
Epoch [2950/15000], Loss: 14.2110, Loss_data: 11.6508, Loss_dt: 1519.6594, Loss_pinn: 10267.0166 , Loss_pinn_ic : 13.8965 106.59306335449219 66147.7265625
type:  validation, total_traj: 10, max_traj 20
Epoch [3000/15000], Loss: 13.9281, Loss_data: 11.5806, Loss_dt: 1418.5948, Loss_pinn: 9146.2334 , Loss_pinn_ic : 14.3348 106.30709075927734 65748.4453125
type:  validation, total_traj: 10, max_traj 20
Epoch [3050/15000], Loss: 13.8034, Loss_data: 11.5614, Loss_dt: 1407.0192, Loss_pinn: 8206.8037 , Loss_pinn_ic : 14.3413 109.3825912475586 67543.1953125
type:  validation, total_traj: 10, max_traj 20
Epoch [3100/15000], Loss: 13.6256, Loss_data: 11.5078, Loss_dt: 1346.4376, Loss_pinn: 7561.9761 , Loss_pinn_ic : 15.1647 107.93136596679688 66561.015625
type:  validation, total_traj: 10, max_traj 20
Epoch [3150/15000], Loss: 13.5851, Loss_data: 11.4477, Loss_dt: 1388.7915, Loss_pinn: 7339.6328 , Loss_pinn_ic : 14.6621 110.89347839355469 68549.265625
type:  validation, total_traj: 10, max_traj 20
Epoch [3200/15000], Loss: 13.2270, Loss_data: 11.2994, Loss_dt: 1211.5919, Loss_pinn: 7011.6772 , Loss_pinn_ic : 14.8297 110.24797821044922 67976.6484375
type:  validation, total_traj: 10, max_traj 20
Epoch [3250/15000], Loss: 13.1010, Loss_data: 11.2219, Loss_dt: 1187.6733, Loss_pinn: 6759.4414 , Loss_pinn_ic : 15.4393 109.18817138671875 67119.265625
type:  validation, total_traj: 10, max_traj 20
Epoch [3300/15000], Loss: 13.1222, Loss_data: 11.1694, Loss_dt: 1270.5085, Loss_pinn: 6664.4565 , Loss_pinn_ic : 15.8765 109.20594024658203 66951.828125
type:  validation, total_traj: 10, max_traj 20
Epoch [3350/15000], Loss: 12.7722, Loss_data: 10.9484, Loss_dt: 1136.1698, Loss_pinn: 6719.8247 , Loss_pinn_ic : 15.5575 109.5682144165039 67149.9921875
type:  validation, total_traj: 10, max_traj 20
Epoch [3400/15000], Loss: 14.0690, Loss_data: 11.2839, Loss_dt: 2054.0076, Loss_pinn: 7150.9478 , Loss_pinn_ic : 15.9137 114.9912109375 71091.4140625
type:  validation, total_traj: 10, max_traj 20
Epoch [3450/15000], Loss: 12.3274, Loss_data: 10.6182, Loss_dt: 1027.9177, Loss_pinn: 6657.3853 , Loss_pinn_ic : 15.4843 111.14863586425781 67842.2265625
Early stopping
Validation loss decreased (175.697723 --> 111.109253).  Saving model ...
Model( and tf values) saved: model/data_dt_pinn_ic/GFL_2nd_orderDynamicNN_1_3454_80000_100000_10000_None_None_1_0.001_0.0001_0.001_Static.pth
Total test trajectories 10
Loss: 75.64179230
MAE Loss: 2.44757009
Total trainable parameters 17026
run <wandb.sdk.wandb_run.Run object at 0x175f6c610>
type:  test, total_traj: 10, max_traj 10
