GFL_2nd_order data
Loading data from:  ./data/GFL_2nd_order/dataset_v1.pkl
/Users/nbhsbgnb/PycharmProjects/PythonProject/PowerPINN/src/nn/nn_dataset.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  training_sample = torch.tensor(training_sample, dtype=torch.float32) # convert the trajectory to tensor
Number of training samples:  80000 Number of validation samples:  10000 Number of testing samples:  10000
Number of different initial conditions for collocation points:  100
['delta', 'omega'] Variables
[[-3.14159, 3.14159], [-60, 60]] Set of values for init conditions
[10, 10] Iterations per value
Shape: (100, 2)
Selected deep learning model:  DynamicNN
[INIT] sample_per_traj = 1000
Number of labeled training data: 80000 Number of collocation points: 100000 Number of collocation points (IC): 100 Number of validation data: 10000
Weights initialized as:  [1, 0, 0, 0]  are updated with scheme:  Static
getting in training
Validation loss decreased (inf --> 60.455639).  Saving model ...
type:  validation, total_traj: 10, max_traj 20
Epoch [50/25000], Loss: 118.9142, Loss_data: 118.9142, Loss_dt: 69657.6797, Loss_pinn: 253418.8438 , Loss_pinn_ic : 591.0231 61.141517639160156 46510.0546875
type:  validation, total_traj: 10, max_traj 20
Epoch [100/25000], Loss: 112.0314, Loss_data: 112.0314, Loss_dt: 69644.6094, Loss_pinn: 142412.4375 , Loss_pinn_ic : 590.5842 59.5625114440918 46500.37890625
type:  validation, total_traj: 10, max_traj 20
Epoch [150/25000], Loss: 107.3709, Loss_data: 107.3709, Loss_dt: 69566.7266, Loss_pinn: 140037.7344 , Loss_pinn_ic : 550.6772 58.04001235961914 46425.26171875
type:  validation, total_traj: 10, max_traj 20
Epoch [200/25000], Loss: 99.7110, Loss_data: 99.7110, Loss_dt: 69112.6953, Loss_pinn: 160663.6406 , Loss_pinn_ic : 476.7108 54.495391845703125 45886.8046875
type:  validation, total_traj: 10, max_traj 20
Epoch [250/25000], Loss: 84.2786, Loss_data: 84.2786, Loss_dt: 65446.7969, Loss_pinn: 147604.0938 , Loss_pinn_ic : 327.9618 44.3933219909668 42314.31640625
type:  validation, total_traj: 10, max_traj 20
Epoch [300/25000], Loss: 68.9126, Loss_data: 68.9126, Loss_dt: 59186.4414, Loss_pinn: 137280.9062 , Loss_pinn_ic : 246.6076 32.912532806396484 34165.64453125
type:  validation, total_traj: 10, max_traj 20
Epoch [350/25000], Loss: 56.6624, Loss_data: 56.6624, Loss_dt: 53478.9336, Loss_pinn: 127774.4297 , Loss_pinn_ic : 193.8617 24.594993591308594 28086.46484375
type:  validation, total_traj: 10, max_traj 20
Epoch [400/25000], Loss: 45.4445, Loss_data: 45.4445, Loss_dt: 48284.2578, Loss_pinn: 145525.1094 , Loss_pinn_ic : 167.1080 16.43263053894043 22661.935546875
type:  validation, total_traj: 10, max_traj 20
Epoch [450/25000], Loss: 37.2455, Loss_data: 37.2455, Loss_dt: 44483.9727, Loss_pinn: 153567.8438 , Loss_pinn_ic : 148.9388 11.479508399963379 19065.76171875
type:  validation, total_traj: 10, max_traj 20
Epoch [500/25000], Loss: 32.2234, Loss_data: 32.2234, Loss_dt: 40946.3750, Loss_pinn: 170004.8438 , Loss_pinn_ic : 141.1304 8.961384773254395 16005.6787109375
type:  validation, total_traj: 10, max_traj 20
Epoch [550/25000], Loss: 28.3291, Loss_data: 28.3291, Loss_dt: 38260.5156, Loss_pinn: 175281.0156 , Loss_pinn_ic : 127.2645 7.530137538909912 14531.1767578125
type:  validation, total_traj: 10, max_traj 20
Epoch [600/25000], Loss: 24.9097, Loss_data: 24.9097, Loss_dt: 35720.9102, Loss_pinn: 173293.3125 , Loss_pinn_ic : 113.2988 7.203895092010498 13991.0400390625
type:  validation, total_traj: 10, max_traj 20
Epoch [650/25000], Loss: 21.9573, Loss_data: 21.9573, Loss_dt: 33430.1289, Loss_pinn: 173353.3125 , Loss_pinn_ic : 94.2818 5.932069778442383 12676.7783203125
type:  validation, total_traj: 10, max_traj 20
Epoch [700/25000], Loss: 19.6815, Loss_data: 19.6815, Loss_dt: 31436.1484, Loss_pinn: 163953.9062 , Loss_pinn_ic : 74.7545 5.21559476852417 11487.20703125
type:  validation, total_traj: 10, max_traj 20
Epoch [750/25000], Loss: 17.6754, Loss_data: 17.6754, Loss_dt: 29670.5391, Loss_pinn: 142628.8125 , Loss_pinn_ic : 64.8014 4.648471832275391 10290.482421875
type:  validation, total_traj: 10, max_traj 20
Epoch [800/25000], Loss: 15.8204, Loss_data: 15.8204, Loss_dt: 28001.4512, Loss_pinn: 141301.4531 , Loss_pinn_ic : 58.2445 4.133029937744141 9289.412109375
type:  validation, total_traj: 10, max_traj 20
Epoch [850/25000], Loss: 13.7703, Loss_data: 13.7703, Loss_dt: 26149.4180, Loss_pinn: 141402.6406 , Loss_pinn_ic : 53.4532 3.5794081687927246 8417.5478515625
type:  validation, total_traj: 10, max_traj 20
Epoch [900/25000], Loss: 12.0645, Loss_data: 12.0645, Loss_dt: 24432.2656, Loss_pinn: 138371.5781 , Loss_pinn_ic : 47.1176 3.2942280769348145 7871.6845703125
type:  validation, total_traj: 10, max_traj 20
Epoch [950/25000], Loss: 10.4030, Loss_data: 10.4030, Loss_dt: 22790.3145, Loss_pinn: 136991.3438 , Loss_pinn_ic : 45.0231 3.139857053756714 7834.4794921875
type:  validation, total_traj: 10, max_traj 20
Epoch [1000/25000], Loss: 9.8455, Loss_data: 9.8455, Loss_dt: 21882.3340, Loss_pinn: 136680.0781 , Loss_pinn_ic : 45.5156 3.3462820053100586 8015.97509765625
type:  validation, total_traj: 10, max_traj 20
Epoch [1050/25000], Loss: 7.9040, Loss_data: 7.9040, Loss_dt: 20049.1504, Loss_pinn: 138954.0469 , Loss_pinn_ic : 39.5324 2.698153018951416 7064.4697265625
type:  validation, total_traj: 10, max_traj 20
Epoch [1100/25000], Loss: 7.4510, Loss_data: 7.4510, Loss_dt: 19164.3086, Loss_pinn: 139186.4062 , Loss_pinn_ic : 38.7601 2.5811102390289307 6796.41552734375
type:  validation, total_traj: 10, max_traj 20
Epoch [1150/25000], Loss: 6.3442, Loss_data: 6.3442, Loss_dt: 17860.7617, Loss_pinn: 137303.6562 , Loss_pinn_ic : 37.1034 2.4568986892700195 6648.28564453125
type:  validation, total_traj: 10, max_traj 20
Epoch [1200/25000], Loss: 5.9930, Loss_data: 5.9930, Loss_dt: 17126.8242, Loss_pinn: 135743.9531 , Loss_pinn_ic : 36.8948 2.62290620803833 6509.98388671875
type:  validation, total_traj: 10, max_traj 20
Epoch [1250/25000], Loss: 5.2923, Loss_data: 5.2923, Loss_dt: 16142.5586, Loss_pinn: 133445.1562 , Loss_pinn_ic : 36.1527 2.3066794872283936 6294.40234375
type:  validation, total_traj: 10, max_traj 20
Epoch [1300/25000], Loss: 4.9850, Loss_data: 4.9850, Loss_dt: 15498.4727, Loss_pinn: 132314.2969 , Loss_pinn_ic : 36.0029 2.354748010635376 6116.60498046875
type:  validation, total_traj: 10, max_traj 20
Epoch [1350/25000], Loss: 4.5641, Loss_data: 4.5641, Loss_dt: 14784.1611, Loss_pinn: 131520.7031 , Loss_pinn_ic : 35.3519 2.201958417892456 5951.45458984375
type:  validation, total_traj: 10, max_traj 20
Epoch [1400/25000], Loss: 4.2660, Loss_data: 4.2660, Loss_dt: 14176.1348, Loss_pinn: 131101.5312 , Loss_pinn_ic : 34.8014 2.137134075164795 5825.9384765625
type:  validation, total_traj: 10, max_traj 20
Epoch [1450/25000], Loss: 4.1511, Loss_data: 4.1511, Loss_dt: 13762.1582, Loss_pinn: 130566.8047 , Loss_pinn_ic : 34.2597 2.133605718612671 5690.841796875
type:  validation, total_traj: 10, max_traj 20
Epoch [1500/25000], Loss: 3.8067, Loss_data: 3.8067, Loss_dt: 13151.0547, Loss_pinn: 129037.4609 , Loss_pinn_ic : 33.2398 2.065197229385376 5584.71826171875
type:  validation, total_traj: 10, max_traj 20
Epoch [1550/25000], Loss: 3.7504, Loss_data: 3.7504, Loss_dt: 12821.7051, Loss_pinn: 127383.2109 , Loss_pinn_ic : 32.8195 2.19769287109375 5575.51611328125
type:  validation, total_traj: 10, max_traj 20
Epoch [1600/25000], Loss: 3.4765, Loss_data: 3.4765, Loss_dt: 12325.6816, Loss_pinn: 125852.5078 , Loss_pinn_ic : 31.6187 2.0101444721221924 5405.9423828125
type:  validation, total_traj: 10, max_traj 20
Epoch [1650/25000], Loss: 3.3340, Loss_data: 3.3340, Loss_dt: 11961.3467, Loss_pinn: 124509.1797 , Loss_pinn_ic : 30.9120 1.9827035665512085 5311.67822265625
type:  validation, total_traj: 10, max_traj 20
Epoch [1700/25000], Loss: 3.3324, Loss_data: 3.3324, Loss_dt: 11770.4414, Loss_pinn: 122159.8984 , Loss_pinn_ic : 30.8301 2.045008897781372 5289.3486328125
type:  validation, total_traj: 10, max_traj 20
Epoch [1750/25000], Loss: 3.0947, Loss_data: 3.0947, Loss_dt: 11357.6904, Loss_pinn: 118827.4375 , Loss_pinn_ic : 29.7457 1.9309154748916626 5143.3037109375
type:  validation, total_traj: 10, max_traj 20
Epoch [1800/25000], Loss: 3.5100, Loss_data: 3.5100, Loss_dt: 11524.1367, Loss_pinn: 115950.0469 , Loss_pinn_ic : 29.9300 1.9500261545181274 5121.97021484375
type:  validation, total_traj: 10, max_traj 20
Epoch [1850/25000], Loss: 2.9245, Loss_data: 2.9245, Loss_dt: 10857.0273, Loss_pinn: 115143.6250 , Loss_pinn_ic : 28.5085 1.8790980577468872 5021.54150390625
type:  validation, total_traj: 10, max_traj 20
Epoch [1900/25000], Loss: 2.8414, Loss_data: 2.8414, Loss_dt: 10607.4521, Loss_pinn: 113751.8359 , Loss_pinn_ic : 28.1325 1.8605685234069824 4957.0263671875
type:  validation, total_traj: 10, max_traj 20
Epoch [1950/25000], Loss: 3.3781, Loss_data: 3.3781, Loss_dt: 10985.7861, Loss_pinn: 112100.8125 , Loss_pinn_ic : 27.7863 2.362705945968628 5462.7568359375
type:  validation, total_traj: 10, max_traj 20
Epoch [2000/25000], Loss: 2.7204, Loss_data: 2.7204, Loss_dt: 10226.1504, Loss_pinn: 111815.5000 , Loss_pinn_ic : 27.3077 1.8185405731201172 4854.16845703125
type:  validation, total_traj: 10, max_traj 20
Epoch [2050/25000], Loss: 2.6571, Loss_data: 2.6571, Loss_dt: 10012.4717, Loss_pinn: 111409.4219 , Loss_pinn_ic : 27.0600 1.7976429462432861 4791.73828125
type:  validation, total_traj: 10, max_traj 20
Epoch [2100/25000], Loss: 3.3137, Loss_data: 3.3137, Loss_dt: 10639.8379, Loss_pinn: 111121.8125 , Loss_pinn_ic : 28.3656 2.0704991817474365 5072.77490234375
type:  validation, total_traj: 10, max_traj 20
Epoch [2150/25000], Loss: 2.5518, Loss_data: 2.5518, Loss_dt: 9699.7832, Loss_pinn: 111176.1953 , Loss_pinn_ic : 26.5126 1.753316044807434 4677.265625
type:  validation, total_traj: 10, max_traj 20
Epoch [2200/25000], Loss: 2.4821, Loss_data: 2.4821, Loss_dt: 9567.2012, Loss_pinn: 111161.4375 , Loss_pinn_ic : 26.1354 1.7294529676437378 4600.08544921875
