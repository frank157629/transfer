GFL_2nd_order data
Loading data from:  ./data/GFL_2nd_order/dataset_v1.pkl
/Users/nbhsbgnb/PycharmProjects/PythonProject/PowerPINN/src/nn/nn_dataset.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  training_sample = torch.tensor(training_sample, dtype=torch.float32) # convert the trajectory to tensor
Number of training samples:  80000 Number of validation samples:  10000 Number of testing samples:  10000
Number of different initial conditions for collocation points:  100
['delta', 'omega'] Variables
[[-3.14159, 3.14159], [-60, 60]] Set of values for init conditions
[10, 10] Iterations per value
Shape: (100, 2)
Selected deep learning model:  DynamicNN
Number of labeled training data: 80000 Number of collocation points: 100000 Number of collocation points (IC): 100 Number of validation data: 10000
Weights initialized as:  [1, 0.001, 0.0001, 0.001]  are updated with scheme:  Static
getting in training
Validation loss decreased (inf --> 142.703156).  Saving model ...
Epoch [50/15000], Loss: 183.4436, Loss_data: 117.9615, Loss_dt: 64830.0586, Loss_pinn: 599.7886 , Loss_pinn_ic : 592.0711 138.2398223876953 77586.0390625
Epoch [100/15000], Loss: 183.0347, Loss_data: 117.5591, Loss_dt: 64830.0039, Loss_pinn: 542.2007 , Loss_pinn_ic : 591.3095 138.29351806640625 77585.78125
Epoch [150/15000], Loss: 182.6579, Loss_data: 117.1814, Loss_dt: 64829.1836, Loss_pinn: 568.6058 , Loss_pinn_ic : 590.4812 138.39614868164062 77584.3671875
Epoch [200/15000], Loss: 181.7246, Loss_data: 116.2441, Loss_dt: 64823.5312, Loss_pinn: 713.8096 , Loss_pinn_ic : 585.6101 137.73934936523438 77575.7734375
