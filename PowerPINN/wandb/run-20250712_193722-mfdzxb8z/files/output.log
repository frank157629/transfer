GFL_2nd_order data
Loading data from:  ./data/GFL_2nd_order/dataset_v1.pkl
/Users/nbhsbgnb/PycharmProjects/PythonProject/PowerPINN/src/nn/nn_dataset.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)
  training_sample = torch.tensor(training_sample, dtype=torch.float32) # convert the trajectory to tensor
Number of training samples:  80000 Number of validation samples:  10000 Number of testing samples:  10000
Number of different initial conditions for collocation points:  100
['delta', 'omega'] Variables
[[-3.14159, 3.14159], [-60, 60]] Set of values for init conditions
[10, 10] Iterations per value
Shape: (100, 2)
Selected deep learning model:  DynamicNN
Number of labeled training data: 80000 Number of collocation points: 100000 Number of collocation points (IC): 100 Number of validation data: 10000
Weights initialized as:  [1, 0.001, 0.0001, 0.001]  are updated with scheme:  Static
getting in training
type:  validation, total_traj: 10, max_traj 20
Epoch [50/25000], Loss: 195.7195, Loss_data: 127.9431, Loss_dt: 67125.0000, Loss_pinn: 657.2738 , Loss_pinn_ic : 585.7110 170.28875732421875 85136.4921875
type:  validation, total_traj: 10, max_traj 20
Epoch [100/25000], Loss: 194.7272, Loss_data: 126.9479, Loss_dt: 67124.2734, Loss_pinn: 701.4121 , Loss_pinn_ic : 584.8452 169.43421936035156 85136.609375
type:  validation, total_traj: 10, max_traj 20
Epoch [150/25000], Loss: 193.2528, Loss_data: 125.4677, Loss_dt: 67119.4375, Loss_pinn: 851.3149 , Loss_pinn_ic : 580.5526 167.4062957763672 85132.9140625
type:  validation, total_traj: 10, max_traj 20
Epoch [200/25000], Loss: 190.9796, Loss_data: 123.2097, Loss_dt: 67102.8750, Loss_pinn: 964.1345 , Loss_pinn_ic : 570.5402 164.41188049316406 85118.109375
type:  validation, total_traj: 10, max_traj 20
Epoch [250/25000], Loss: 187.0053, Loss_data: 119.3242, Loss_dt: 67035.5156, Loss_pinn: 1041.5728 , Loss_pinn_ic : 541.3986 160.16285705566406 85059.421875
type:  validation, total_traj: 10, max_traj 20
Epoch [300/25000], Loss: 178.1061, Loss_data: 110.8530, Loss_dt: 66665.2578, Loss_pinn: 1316.8741 , Loss_pinn_ic : 456.1825 151.4276580810547 84790.828125
type:  validation, total_traj: 10, max_traj 20
Epoch [350/25000], Loss: 166.2910, Loss_data: 100.2439, Loss_dt: 65595.7031, Loss_pinn: 1200.5712 , Loss_pinn_ic : 331.4093 138.93267822265625 84270.2109375
type:  validation, total_traj: 10, max_traj 20
Epoch [400/25000], Loss: 151.7580, Loss_data: 88.4974, Loss_dt: 62905.1094, Loss_pinn: 1318.0275 , Loss_pinn_ic : 223.6867 123.91812133789062 82177.890625
type:  validation, total_traj: 10, max_traj 20
Epoch [450/25000], Loss: 134.8099, Loss_data: 76.4293, Loss_dt: 58064.4375, Loss_pinn: 1553.9983 , Loss_pinn_ic : 160.7702 106.38147735595703 76814.78125
type:  validation, total_traj: 10, max_traj 20
Epoch [500/25000], Loss: 120.8450, Loss_data: 67.7175, Loss_dt: 52785.6719, Loss_pinn: 2165.6985 , Loss_pinn_ic : 125.2483 95.80317687988281 73275.4921875
type:  validation, total_traj: 10, max_traj 20
Epoch [550/25000], Loss: 112.8885, Loss_data: 62.7600, Loss_dt: 49784.5430, Loss_pinn: 2226.9849 , Loss_pinn_ic : 121.2495 88.44773864746094 68938.2109375
type:  validation, total_traj: 10, max_traj 20
Epoch [600/25000], Loss: 102.5989, Loss_data: 56.4313, Loss_dt: 45895.6758, Loss_pinn: 1510.7213 , Loss_pinn_ic : 120.8519 84.71002960205078 67525.8125
type:  validation, total_traj: 10, max_traj 20
Epoch [650/25000], Loss: 95.5523, Loss_data: 52.4343, Loss_dt: 42854.6250, Loss_pinn: 1588.2383 , Loss_pinn_ic : 104.6340 80.469970703125 63997.5859375
type:  validation, total_traj: 10, max_traj 20
Epoch [700/25000], Loss: 88.5764, Loss_data: 48.9236, Loss_dt: 39354.4688, Loss_pinn: 2352.1064 , Loss_pinn_ic : 63.1458 79.03507232666016 61661.9453125
type:  validation, total_traj: 10, max_traj 20
Epoch [750/25000], Loss: 82.6975, Loss_data: 45.8494, Loss_dt: 36518.3867, Loss_pinn: 2753.3594 , Loss_pinn_ic : 54.3390 79.63935089111328 61554.01953125
type:  validation, total_traj: 10, max_traj 20
Epoch [800/25000], Loss: 77.5263, Loss_data: 43.2207, Loss_dt: 33945.7656, Loss_pinn: 3165.7415 , Loss_pinn_ic : 43.2235 78.57939910888672 60090.16796875
type:  validation, total_traj: 10, max_traj 20
Epoch [850/25000], Loss: 72.3743, Loss_data: 40.4418, Loss_dt: 31558.8418, Loss_pinn: 3338.5393 , Loss_pinn_ic : 39.8374 78.04568481445312 58949.18359375
